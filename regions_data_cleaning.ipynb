{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regions Data Cleaning Notebook\n",
    "\n",
    "This notebook analyzes and cleans the regions data by removing entries with \"Na\" values for districts and states.\n",
    "\n",
    "## Goals:\n",
    "1. Load and explore the regions data\n",
    "2. Identify entries with \"Na\" values\n",
    "3. Develop cleaning strategy\n",
    "4. Apply cleaning and verify results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import json\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import re\n",
    "\n",
    "print(\"=== Regions Data Cleaning ===\")\n",
    "print(\"Loading and analyzing regions data...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the regions data\n",
    "with open('apps/web/public/regions_data.json', 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "print(f\"Loaded data with {len(data['regions'])} regions\")\n",
    "print(f\"Data keys: {list(data.keys())}\")\n",
    "print(f\"Summary: {data['summary']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check for Na values (case insensitive)\n",
    "def is_na_value(value):\n",
    "    \"\"\"Check if a value represents Na/None/missing\"\"\"\n",
    "    if value is None:\n",
    "        return True\n",
    "    if isinstance(value, str):\n",
    "        # Check for various Na representations\n",
    "        na_patterns = [\n",
    "            r'^\\s*na\\s*$',\n",
    "            r'^\\s*n/a\\s*$', \n",
    "            r'^\\s*none\\s*$',\n",
    "            r'^\\s*null\\s*$',\n",
    "            r'^\\s*-\\s*$',\n",
    "            r'^\\s*$'  # empty string\n",
    "        ]\n",
    "        return any(re.match(pattern, value, re.IGNORECASE) for pattern in na_patterns)\n",
    "    return False\n",
    "\n",
    "# Analyze the data for Na values\n",
    "na_issues = {\n",
    "    'states_with_na': [],\n",
    "    'districts_with_na': [],\n",
    "    'cities_with_na': [],\n",
    "    'total_na_districts': 0,\n",
    "    'total_na_cities': 0\n",
    "}\n",
    "\n",
    "print(\"Scanning for Na values...\")\n",
    "\n",
    "for region_idx, region in enumerate(data['regions']):\n",
    "    state_name = region['name']\n",
    "    \n",
    "    # Check if state name is Na\n",
    "    if is_na_value(state_name):\n",
    "        na_issues['states_with_na'].append({\n",
    "            'index': region_idx,\n",
    "            'name': state_name,\n",
    "            'type': 'state'\n",
    "        })\n",
    "    \n",
    "    # Check districts within this state\n",
    "    for district_idx, district in enumerate(region['districts']):\n",
    "        district_name = district['name']\n",
    "        \n",
    "        if is_na_value(district_name):\n",
    "            na_issues['districts_with_na'].append({\n",
    "                'state_index': region_idx,\n",
    "                'state_name': state_name,\n",
    "                'district_index': district_idx,\n",
    "                'district_name': district_name,\n",
    "                'type': 'district'\n",
    "            })\n",
    "            na_issues['total_na_districts'] += 1\n",
    "        \n",
    "        # Check cities within this district\n",
    "        for city_idx, city in enumerate(district['cities']):\n",
    "            city_name = city['name']\n",
    "            \n",
    "            if is_na_value(city_name):\n",
    "                na_issues['cities_with_na'].append({\n",
    "                    'state_index': region_idx,\n",
    "                    'state_name': state_name,\n",
    "                    'district_index': district_idx,\n",
    "                    'district_name': district_name,\n",
    "                    'city_index': city_idx,\n",
    "                    'city_name': city_name,\n",
    "                    'type': 'city'\n",
    "                })\n",
    "                na_issues['total_na_cities'] += 1\n",
    "\n",
    "print(f\"Analysis complete!\")\n",
    "print(f\"States with Na: {len(na_issues['states_with_na'])}\")\n",
    "print(f\"Districts with Na: {na_issues['total_na_districts']}\")\n",
    "print(f\"Cities with Na: {na_issues['total_na_cities']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display detailed results of Na analysis\n",
    "print(\"=== DETAILED NA ANALYSIS ===\")\n",
    "print()\n",
    "\n",
    "if na_issues['states_with_na']:\n",
    "    print(\"STATES WITH NA VALUES:\")\n",
    "    for state in na_issues['states_with_na']:\n",
    "        print(f\"  - Index {state['index']}: '{state['name']}'\")\n",
    "    print()\n",
    "else:\n",
    "    print(\"✅ No states with Na values found\")\n",
    "    print()\n",
    "\n",
    "if na_issues['districts_with_na']:\n",
    "    print(f\"DISTRICTS WITH NA VALUES ({na_issues['total_na_districts']} total):\")\n",
    "    for district in na_issues['districts_with_na'][:10]:  # Show first 10\n",
    "        print(f\"  - State: {district['state_name']}, District: '{district['district_name']}'\")\n",
    "    if len(na_issues['districts_with_na']) > 10:\n",
    "        print(f\"  ... and {len(na_issues['districts_with_na']) - 10} more\")\n",
    "    print()\n",
    "else:\n",
    "    print(\"✅ No districts with Na values found\")\n",
    "    print()\n",
    "\n",
    "if na_issues['cities_with_na']:\n",
    "    print(f\"CITIES WITH NA VALUES ({na_issues['total_na_cities']} total):\")\n",
    "    for city in na_issues['cities_with_na'][:10]:  # Show first 10\n",
    "        print(f\"  - State: {city['state_name']}, District: {city['district_name']}, City: '{city['city_name']}'\")\n",
    "    if len(na_issues['cities_with_na']) > 10:\n",
    "        print(f\"  ... and {len(na_issues['cities_with_na']) - 10} more\")\n",
    "    print()\n",
    "else:\n",
    "    print(\"✅ No cities with Na values found\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a comprehensive cleaning strategy\n",
    "def clean_regions_data(original_data):\n",
    "    \"\"\"\n",
    "    Clean the regions data by:\n",
    "    1. Removing states with Na names\n",
    "    2. Removing districts with Na names from valid states\n",
    "    3. Removing cities with Na names from valid districts\n",
    "    4. Removing empty districts (no cities after cleaning)\n",
    "    5. Removing empty states (no districts after cleaning)\n",
    "    \"\"\"\n",
    "    \n",
    "    cleaned_data = {\n",
    "        'summary': original_data['summary'].copy(),\n",
    "        'regions': []\n",
    "    }\n",
    "    \n",
    "    states_removed = 0\n",
    "    districts_removed = 0\n",
    "    cities_removed = 0\n",
    "    \n",
    "    print(\"Starting data cleaning process...\")\n",
    "    \n",
    "    for region in original_data['regions']:\n",
    "        state_name = region['name']\n",
    "        \n",
    "        # Skip states with Na names\n",
    "        if is_na_value(state_name):\n",
    "            states_removed += 1\n",
    "            print(f\"  ❌ Removing state with Na name: '{state_name}'\")\n",
    "            continue\n",
    "        \n",
    "        # Process districts within this valid state\n",
    "        valid_districts = []\n",
    "        \n",
    "        for district in region['districts']:\n",
    "            district_name = district['name']\n",
    "            \n",
    "            # Skip districts with Na names\n",
    "            if is_na_value(district_name):\n",
    "                districts_removed += 1\n",
    "                print(f\"    ❌ Removing district with Na name: '{district_name}' (State: {state_name})\")\n",
    "                continue\n",
    "            \n",
    "            # Process cities within this valid district\n",
    "            valid_cities = []\n",
    "            \n",
    "            for city in district['cities']:\n",
    "                city_name = city['name']\n",
    "                \n",
    "                # Skip cities with Na names\n",
    "                if is_na_value(city_name):\n",
    "                    cities_removed += 1\n",
    "                    print(f\"      ❌ Removing city with Na name: '{city_name}' (District: {district_name})\")\n",
    "                    continue\n",
    "                \n",
    "                valid_cities.append(city)\n",
    "            \n",
    "            # Only add district if it has valid cities\n",
    "            if valid_cities:\n",
    "                cleaned_district = {\n",
    "                    'name': district_name,\n",
    "                    'type': district['type'],\n",
    "                    'cities': valid_cities\n",
    "                }\n",
    "                valid_districts.append(cleaned_district)\n",
    "            else:\n",
    "                districts_removed += 1\n",
    "                print(f\"    ❌ Removing empty district: '{district_name}' (no valid cities)\")\n",
    "        \n",
    "        # Only add state if it has valid districts\n",
    "        if valid_districts:\n",
    "            cleaned_region = {\n",
    "                'name': state_name,\n",
    "                'type': region['type'],\n",
    "                'districts': valid_districts\n",
    "            }\n",
    "            cleaned_data['regions'].append(cleaned_region)\n",
    "        else:\n",
    "            states_removed += 1\n",
    "            print(f\"  ❌ Removing empty state: '{state_name}' (no valid districts)\")\n",
    "    \n",
    "    # Update summary\n",
    "    total_districts = sum(len(region['districts']) for region in cleaned_data['regions'])\n",
    "    total_cities = sum(len(district['cities']) for region in cleaned_data['regions'] for district in region['districts'])\n",
    "    \n",
    "    cleaned_data['summary'] = {\n",
    "        'total_states': len(cleaned_data['regions']),\n",
    "        'total_districts': total_districts,\n",
    "        'total_cities': total_cities\n",
    "    }\n",
    "    \n",
    "    return cleaned_data, {\n",
    "        'states_removed': states_removed,\n",
    "        'districts_removed': districts_removed,\n",
    "        'cities_removed': cities_removed\n",
    "    }\n",
    "\n",
    "print(\"Cleaning function defined. Ready to apply!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the cleaning function\n",
    "print(\"=== APPLYING DATA CLEANING ===\")\n",
    "print()\n",
    "\n",
    "original_summary = data['summary']\n",
    "print(f\"Original data:\")\n",
    "print(f\"  States: {original_summary['total_states']}\")\n",
    "print(f\"  Districts: {original_summary['total_districts']}\")\n",
    "print(f\"  Cities: {original_summary['total_cities']}\")\n",
    "print()\n",
    "\n",
    "cleaned_data, removal_stats = clean_regions_data(data)\n",
    "\n",
    "print()\n",
    "print(\"=== CLEANING RESULTS ===\")\n",
    "print(f\"States removed: {removal_stats['states_removed']}\")\n",
    "print(f\"Districts removed: {removal_stats['districts_removed']}\")\n",
    "print(f\"Cities removed: {removal_stats['cities_removed']}\")\n",
    "print()\n",
    "\n",
    "cleaned_summary = cleaned_data['summary']\n",
    "print(f\"Cleaned data:\")\n",
    "print(f\"  States: {cleaned_summary['total_states']}\")\n",
    "print(f\"  Districts: {cleaned_summary['total_districts']}\")\n",
    "print(f\"  Cities: {cleaned_summary['total_cities']}\")\n",
    "print()\n",
    "\n",
    "print(f\"Net change:\")\n",
    "print(f\"  States: {cleaned_summary['total_states'] - original_summary['total_states']:+d}\")\n",
    "print(f\"  Districts: {cleaned_summary['total_districts'] - original_summary['total_districts']:+d}\")\n",
    "print(f\"  Cities: {cleaned_summary['total_cities'] - original_summary['total_cities']:+d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show sample of cleaned data\n",
    "print(\"=== SAMPLE OF CLEANED DATA ===\")\n",
    "print()\n",
    "\n",
    "for i, region in enumerate(cleaned_data['regions'][:3]):\n",
    "    print(f\"{i+1}. State: {region['name']} (Type: {region['type']})\")\n",
    "    print(f\"   Districts: {len(region['districts'])}\")\n",
    "    \n",
    "    for j, district in enumerate(region['districts'][:2]):\n",
    "        print(f\"   {j+1}. District: {district['name']} (Type: {district['type']})\")\n",
    "        print(f\"      Cities: {len(district['cities'])}\")\n",
    "        \n",
    "        for k, city in enumerate(district['cities'][:2]):\n",
    "            print(f\"      {k+1}. City: {city['name']} (Type: {city['type']})\")\n",
    "        \n",
    "        if len(district['cities']) > 2:\n",
    "            print(f\"      ... and {len(district['cities']) - 2} more cities\")\n",
    "    \n",
    "    if len(region['districts']) > 2:\n",
    "        print(f\"   ... and {len(region['districts']) - 2} more districts\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create backup and save cleaned data\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "\n",
    "# Create a backup with timestamp\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "backup_filename = f'apps/web/public/regions_data_before_cleaning_{timestamp}.json'\n",
    "\n",
    "shutil.copy('apps/web/public/regions_data.json', backup_filename)\n",
    "print(f\"✅ Created backup: {backup_filename}\")\n",
    "\n",
    "# Save the cleaned data\n",
    "with open('apps/web/public/regions_data.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(cleaned_data, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(\"✅ Saved cleaned data to regions_data.json\")\n",
    "print()\n",
    "print(\"=== FINAL VERIFICATION ===\")\n",
    "\n",
    "# Load and verify the saved data\n",
    "with open('apps/web/public/regions_data.json', 'r', encoding='utf-8') as f:\n",
    "    verification_data = json.load(f)\n",
    "\n",
    "print(f\"Verification successful!\")\n",
    "print(f\"Saved data contains: {verification_data['summary']}\")\n",
    "print(f\"Data integrity: {'✅ PASS' if verification_data == cleaned_data else '❌ FAIL'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook successfully:\n",
    "1. ✅ Analyzed the regions data for Na values\n",
    "2. ✅ Identified problematic entries\n",
    "3. ✅ Applied comprehensive cleaning strategy\n",
    "4. ✅ Created backups before modification\n",
    "5. ✅ Saved cleaned dataset\n",
    "6. ✅ Verified data integrity\n",
    "\n",
    "The cleaned dataset now contains only valid states, districts, and cities with proper names."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}